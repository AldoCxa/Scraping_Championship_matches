{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center> Scraping Championship data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of this notebook is to get the matches data from <b> England Championship.</b> We will use the webpage www.flashscore.com to get all the information.  To make the web scraping we will use Selenium to remotly control the webpage and BeautifulSoup to save the HTML code, which contains the information we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup as bs #import beautiful soup\n",
    "\n",
    "#! pip install selenium \n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know the structure of the page we are going to scrape, to do that we are going to open this match : <a href=https://www.flashscore.com/match/faNi9ZPf/#match-statistics;0> Reading vs Birmingham</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a browser. You have to check the version of the browser you watn to use (chrome, firefox, edge, etc.) and look for the 'driver'. Once you have the right driver, save it in the location of your preference, it will be necesary to know the File route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(executable_path = r'C:\\Users\\Aldo\\Documents\\Data science\\Projects\\web_scraping\\chromedriver87.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "put the url page in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flashscore.com/match/faNi9ZPf/#match-statistics;0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a BeautifulSoup element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the webpage\n",
    "browser.get(url)\n",
    "#Save the html code in a variable\n",
    "html = browser.page_source\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "\n",
    "#close all pages\n",
    "#browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Getting data from the webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the HTML code save as a BeautifulSoup object, it is posible to look for specifict data.We can look for an element by the id or the class, just consider that  there are multiple elements in the same class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, look for the id of the element you want to get, it could be done by usinig the inspect mode of the browser where you open the page \n",
    "(Ctrl + Shift + C). In this case, we will get the  date by the id:  'utime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09.12.2020 13:45'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = soup.findAll('div',{'id':'utime'})[0]\n",
    "date = date.text\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Championship - Round 17'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = soup.findAll('span',{'class':'description__country'})[0].a.text\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the home name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reading'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home = soup.findAll('div',{'class':'team-text tname-home'})[0]\n",
    "home = home.a.text\n",
    "home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting away name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Birmingham'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away = soup.findAll('div',{'class':'team-text tname-away'})[0]\n",
    "away = away.a.text\n",
    "away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home score: 1\n",
      "away score: 2\n"
     ]
    }
   ],
   "source": [
    "match_result = soup.find_all(\"div\", {\"id\":\"event_detail_current_result\"})[0]\n",
    "scores = match_result.findAll('span',{'class':'scoreboard'})\n",
    "score = [score.text for score in scores]\n",
    "score\n",
    "home_score = score[0]\n",
    "away_score = score[1]\n",
    "\n",
    "\n",
    "print ('home score: '+ home_score)\n",
    "print ('away score: '+ away_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "Now that we have the basic match info, it is time to get the match statistics. The Id  we will use is the full time match\n",
    "\n",
    "<p>full time match id: <b> 'tab-statistics-0-statistic' </b> </p> \n",
    "<p>first half time id:<b> 'tab-statistics-1-statistic' </b> </p>\n",
    "<p>second half time id:<b> 'tab-statistics-2-statistic' </b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = soup.findAll('div', {'id':'tab-statistics-0-statistic'})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['64%',\n",
       " '11',\n",
       " '2',\n",
       " '8',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '9',\n",
       " '0',\n",
       " '1',\n",
       " '577',\n",
       " '15',\n",
       " '89',\n",
       " '28']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_values = match.findAll('div', {'class':'statText statText--homeValue'})\n",
    "home_value = [home.text for home in home_values]\n",
    "home_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['36%',\n",
       " '5',\n",
       " '3',\n",
       " '0',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '25',\n",
       " '1',\n",
       " '5',\n",
       " '318',\n",
       " '20',\n",
       " '127',\n",
       " '43']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away_values = match.findAll('div', {'class':'statText statText--awayValue'})\n",
    "away_value = [away.text for away in away_values]\n",
    "away_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all data in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Create a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the columns will be the match stats titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Home Ball Possession',\n",
       " 'Home Goal Attempts',\n",
       " 'Home Shots on Goal',\n",
       " 'Home Shots off Goal',\n",
       " 'Home Blocked Shots',\n",
       " 'Home Corner Kicks',\n",
       " 'Home Offsides',\n",
       " 'Home Goalkeeper Saves',\n",
       " 'Home Fouls',\n",
       " 'Home Red Cards',\n",
       " 'Home Yellow Cards',\n",
       " 'Home Total Passes',\n",
       " 'Home Tackles',\n",
       " 'Home Attacks',\n",
       " 'Home Dangerous Attacks',\n",
       " 'Away Ball Possession',\n",
       " 'Away Goal Attempts',\n",
       " 'Away Shots on Goal',\n",
       " 'Away Shots off Goal',\n",
       " 'Away Blocked Shots',\n",
       " 'Away Corner Kicks',\n",
       " 'Away Offsides',\n",
       " 'Away Goalkeeper Saves',\n",
       " 'Away Fouls',\n",
       " 'Away Red Cards',\n",
       " 'Away Yellow Cards',\n",
       " 'Away Total Passes',\n",
       " 'Away Tackles',\n",
       " 'Away Attacks',\n",
       " 'Away Dangerous Attacks']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = match.findAll('div',{'class':'statText statText--titleValue'})\n",
    "#List with all the titles\n",
    "actual_titltes = [title.text for title in titles]\n",
    "\n",
    "#add a prefix to identefy which team the stat belongs to.\n",
    "home_titles = ['Home ' + sub for sub in actual_titltes]\n",
    "away_titles = ['Away ' + sub for sub in actual_titltes]\n",
    "all_titles = home_titles + away_titles\n",
    "\n",
    "all_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the match info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Description', 'Date', 'Home', 'Away', 'FTHG', 'FTAG']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_columns = ['Description','Date','Home','Away','FTHG','FTAG'] \n",
    "info_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list with all colum names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = info_columns + all_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an empty dataframe with the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>Home Ball Possession</th>\n",
       "      <th>Home Goal Attempts</th>\n",
       "      <th>Home Shots on Goal</th>\n",
       "      <th>Home Shots off Goal</th>\n",
       "      <th>...</th>\n",
       "      <th>Away Corner Kicks</th>\n",
       "      <th>Away Offsides</th>\n",
       "      <th>Away Goalkeeper Saves</th>\n",
       "      <th>Away Fouls</th>\n",
       "      <th>Away Red Cards</th>\n",
       "      <th>Away Yellow Cards</th>\n",
       "      <th>Away Total Passes</th>\n",
       "      <th>Away Tackles</th>\n",
       "      <th>Away Attacks</th>\n",
       "      <th>Away Dangerous Attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Description, Date, Home, Away, FTHG, FTAG, Home Ball Possession, Home Goal Attempts, Home Shots on Goal, Home Shots off Goal, Home Blocked Shots, Home Corner Kicks, Home Offsides, Home Goalkeeper Saves, Home Fouls, Home Red Cards, Home Yellow Cards, Home Total Passes, Home Tackles, Home Attacks, Home Dangerous Attacks, Away Ball Possession, Away Goal Attempts, Away Shots on Goal, Away Shots off Goal, Away Blocked Shots, Away Corner Kicks, Away Offsides, Away Goalkeeper Saves, Away Fouls, Away Red Cards, Away Yellow Cards, Away Total Passes, Away Tackles, Away Attacks, Away Dangerous Attacks]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=all_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list with all the values, in the same order as the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_data = [description, date, home, away, home_score, away_score]\n",
    "\n",
    "all_values = match_data + home_value + away_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dictionary, it will be used to fill the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Description': 'Championship - Round 17', 'Date': '09.12.2020 13:45', 'Home': 'Reading', 'Away': 'Birmingham', 'FTHG': '1', 'FTAG': '2', 'Home Ball Possession': '64%', 'Home Goal Attempts': '11', 'Home Shots on Goal': '2', 'Home Shots off Goal': '8', 'Home Blocked Shots': '1', 'Home Corner Kicks': '4', 'Home Offsides': '1', 'Home Goalkeeper Saves': '1', 'Home Fouls': '9', 'Home Red Cards': '0', 'Home Yellow Cards': '1', 'Home Total Passes': '577', 'Home Tackles': '15', 'Home Attacks': '89', 'Home Dangerous Attacks': '28', 'Away Ball Possession': '36%', 'Away Goal Attempts': '5', 'Away Shots on Goal': '3', 'Away Shots off Goal': '0', 'Away Blocked Shots': '2', 'Away Corner Kicks': '1', 'Away Offsides': '2', 'Away Goalkeeper Saves': '1', 'Away Fouls': '25', 'Away Red Cards': '1', 'Away Yellow Cards': '5', 'Away Total Passes': '318', 'Away Tackles': '20', 'Away Attacks': '127', 'Away Dangerous Attacks': '43'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keys_list = all_columns \n",
    "values_list = all_values\n",
    "zip_iterator = zip(keys_list, values_list)\n",
    "match_dictionary = dict(zip_iterator)\n",
    "\n",
    "print(match_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the first row of the dataframe with the info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>Home Ball Possession</th>\n",
       "      <th>Home Goal Attempts</th>\n",
       "      <th>Home Shots on Goal</th>\n",
       "      <th>Home Shots off Goal</th>\n",
       "      <th>...</th>\n",
       "      <th>Away Corner Kicks</th>\n",
       "      <th>Away Offsides</th>\n",
       "      <th>Away Goalkeeper Saves</th>\n",
       "      <th>Away Fouls</th>\n",
       "      <th>Away Red Cards</th>\n",
       "      <th>Away Yellow Cards</th>\n",
       "      <th>Away Total Passes</th>\n",
       "      <th>Away Tackles</th>\n",
       "      <th>Away Attacks</th>\n",
       "      <th>Away Dangerous Attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Championship - Round 17</td>\n",
       "      <td>09.12.2020 13:45</td>\n",
       "      <td>Reading</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64%</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>318</td>\n",
       "      <td>20</td>\n",
       "      <td>127</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Description              Date     Home        Away FTHG FTAG  \\\n",
       "0  Championship - Round 17  09.12.2020 13:45  Reading  Birmingham    1    2   \n",
       "\n",
       "  Home Ball Possession Home Goal Attempts Home Shots on Goal  \\\n",
       "0                  64%                 11                  2   \n",
       "\n",
       "  Home Shots off Goal  ... Away Corner Kicks Away Offsides  \\\n",
       "0                   8  ...                 1             2   \n",
       "\n",
       "  Away Goalkeeper Saves Away Fouls Away Red Cards Away Yellow Cards  \\\n",
       "0                     1         25              1                 5   \n",
       "\n",
       "  Away Total Passes Away Tackles Away Attacks Away Dangerous Attacks  \n",
       "0               318           20          127                     43  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.append( match_dictionary,  ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and here we have all the match details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping multiple pages\n",
    "\n",
    "Now that we understood how to get the data from a unique match, the next step is to do the same on multiple matches. To do that, we are going to open the webpage with all the matches and create a list with all the match ids (that lis will be called \"Match_ids\"), then we will use the list to locate the element with that id and click on it, that will open the match details, but that new page is NOT the one that contains the data we want. it is necesary another click on \"statistics\" to open the the right window.\n",
    "\n",
    "Once we get in the righ window, we will use that page to create a BeautifoulSoup Object and save it in a list, that list will be called \"list_soups\" and will be used to get the description and match details. Repet this proces for each id. \n",
    "\n",
    "Finally we will create a dataframe and fill it with the data from all the ids and save it as an csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import extra libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "\n",
    "chrome_options.add_argument('disable-notifications')\n",
    "chrome_options.add_argument('--disable-infobars')\n",
    "chrome_options.add_argument('start-maximized')\n",
    "# Pass the argument 1 to allow and 2 to block\n",
    "chrome_options.add_experimental_option(\"prefs\", { \n",
    "    \"profile.default_content_setting_values.notifications\": 2\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ids of each match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a selenium object to navigate in the main page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(executable_path = r'C:\\Users\\Aldo\\Documents\\Data science\\Projects\\web_scraping\\chromedriver87.exe')\n",
    "url_main = 'https://www.flashscore.com/football/england/championship/results/'\n",
    "browser.get(url_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Creating the BeautifulSoup object, make sure to click on \"show more matches\" to load the full page, otherwise the list will be incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_index = browser.page_source\n",
    "soup_index = bs(html_index , 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for the ids from all the matches, these ids will be used to 'click' in the match and get the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_match = soup_index.findAll('div',{'class', 'event__match event__match--static event__match--oneLine'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List lenght: 198\n"
     ]
    }
   ],
   "source": [
    "Match_ids = [ event_id['id'] for event_id in event_match ]\n",
    "\n",
    "print('List lenght: '+ str(len(Match_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "double click here to see how to save the list\n",
    "<!--\n",
    "#Save the List as a file\n",
    "with open(\"Match_ids\", \"w\") as file:\n",
    "    file.write(str(Match_ids))\n",
    "\n",
    "#Load the List file \n",
    "file1 = open(\"Match_ids\", \"r\")\n",
    "file_content= file1.read()\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the id of every match, it is posible to click on those elements, To do that we create a new driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = r'C:\\Users\\Aldo\\Documents\\Data science\\Projects\\web_scraping\\chromedriver87.exe',\n",
    "                         options = chrome_options)\n",
    "\n",
    "url_main = 'https://www.flashscore.com/football/england/championship/results/'\n",
    "driver.implicitly_wait(5)\n",
    "driver.get(url_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "click on \"show more matches\" to load the complete page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-b3d5c76493ef>:4: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(wb)\n"
     ]
    }
   ],
   "source": [
    "#to make sure the driver is focus on the page...\n",
    "\n",
    "wb = driver.window_handles[0]\n",
    "driver.switch_to_window(wb)\n",
    "\n",
    "#match = driver.find_element_by_id(match_id)\n",
    "#match.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g_1_GEB07Df7',\n",
       " 'g_1_rL3nVGnE',\n",
       " 'g_1_2NJmTfHQ',\n",
       " 'g_1_bg5JNYvl',\n",
       " 'g_1_YBcWKWO6']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To see a fast demostration you can only use the first 5 elements of the list. or run the cplete list.\n",
    "Match_ids[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-b612784bdfba>:23: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(wa)\n",
      "<ipython-input-37-b612784bdfba>:33: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(wb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "total Soups: 5\n",
      " \n",
      "total error 0\n",
      "Error list: []\n"
     ]
    }
   ],
   "source": [
    "#scraping code\n",
    "error_list = []\n",
    "list_soups = []\n",
    "wb = driver.window_handles[0]\n",
    "c=0\n",
    "\n",
    "for match_id in Match_ids[0:5]:\n",
    "    element = driver.find_element_by_id(match_id) \n",
    "    ActionChains(driver).move_to_element(element).perform() #go to the element to 'click'\n",
    "    \n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, match_id))\n",
    "        )\n",
    "        element.click()\n",
    "    except:\n",
    "        print('error identifying Match_id ['+ str(c) + '] :' + match_id)\n",
    "    \n",
    "    try:\n",
    "        wa = driver.window_handles[-1] \n",
    "        driver.switch_to_window(wa)  #Focus on the new page\n",
    "        #click on statistics\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'li-match-statistics'))\n",
    "        )\n",
    "        element.click()\n",
    "        sleep(4)\n",
    "        soup_match = bs(driver.page_source , 'html.parser') \n",
    "        list_soups.append(soup_match) \n",
    "        driver.close()\n",
    "        driver.switch_to_window(wb) #go back to the main page\n",
    "    except:\n",
    "        driver.switch_to_window(wb)\n",
    "        error_list.append(match_id)\n",
    "    sleep(4)\n",
    "    c = c +1\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print('total Soups: ' + str(len(list_soups)) )\n",
    "print(' ')\n",
    "print('total error ' + str(len(error_list)))\n",
    "print('Error list: ' + str(error_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read it in case of error:</b> \n",
    "An error in this code means that the match data was not Collected, it could be for some reasons.\n",
    "\n",
    "in some cases the id is NOT located becouse the browser was manually manipulated while the code was runing, a bad internet conection, or the computer entered into suspended mode due the inactivity, sometimes the match does not have the statistics window and the BeautifulSoup can NOT be created. Whichever the case is, a error list is created with the ids that does NOT collect the match data,  and you can use that list to run the code (#scraping code) again with just those ids.\n",
    "\n",
    "Before runing the code again;\n",
    "1. You can save the data you already got in a dataframe  and append the new data later (Go forward, it is explained in this notebook).\n",
    "2. Or you can create a new soup list (with another name) to save the new BeautifulSoup objects and combine the lists later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the error list to run the code again, after saving the data you already have \n",
    "Match_ids = error_list\n",
    "len(Match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Match_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " double click to see how to get the titles\n",
    "\n",
    "<!-- \n",
    "\n",
    "browser = webdriver.Chrome(executable_path = r'C:\\Users\\Aldo\\Documents\\Data science\\Projects\\web_scraping\\chromedriver87.exe')\n",
    "url='https://www.flashscore.com/match/faNi9ZPf/#match-statistics;0'\n",
    "browser.get(url)\n",
    "html = browser.page_source\n",
    "soup = bs(html, 'html.parser')\n",
    "match = soup.findAll('div', {'id':'tab-statistics-0-statistic'})[0]\n",
    "titles = match.findAll('div',{'class':'statText statText--titleValue'})\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "actual_titltes = [title.text for title in titles] \n",
    "\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List with all the titles\n",
    "actual_titltes =[\n",
    " 'Ball Possession',\n",
    " 'Goal Attempts',\n",
    " 'Shots on Goal',\n",
    " 'Shots off Goal',\n",
    " 'Blocked Shots',\n",
    " 'Corner Kicks',\n",
    " 'Offsides',\n",
    " 'Goalkeeper Saves',\n",
    " 'Fouls',\n",
    " 'Red Cards',\n",
    " 'Yellow Cards',\n",
    " 'Total Passes',\n",
    " 'Tackles',\n",
    " 'Attacks',\n",
    " 'Dangerous Attacks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empy dataframe with the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>Home Ball Possession</th>\n",
       "      <th>Home Goal Attempts</th>\n",
       "      <th>Home Shots on Goal</th>\n",
       "      <th>Home Shots off Goal</th>\n",
       "      <th>...</th>\n",
       "      <th>Away Corner Kicks</th>\n",
       "      <th>Away Offsides</th>\n",
       "      <th>Away Goalkeeper Saves</th>\n",
       "      <th>Away Fouls</th>\n",
       "      <th>Away Red Cards</th>\n",
       "      <th>Away Yellow Cards</th>\n",
       "      <th>Away Total Passes</th>\n",
       "      <th>Away Tackles</th>\n",
       "      <th>Away Attacks</th>\n",
       "      <th>Away Dangerous Attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Info, Date, Home, Away, FTHG, FTAG, Home Ball Possession, Home Goal Attempts, Home Shots on Goal, Home Shots off Goal, Home Blocked Shots, Home Corner Kicks, Home Offsides, Home Goalkeeper Saves, Home Fouls, Home Red Cards, Home Yellow Cards, Home Total Passes, Home Tackles, Home Attacks, Home Dangerous Attacks, Away Ball Possession, Away Goal Attempts, Away Shots on Goal, Away Shots off Goal, Away Blocked Shots, Away Corner Kicks, Away Offsides, Away Goalkeeper Saves, Away Fouls, Away Red Cards, Away Yellow Cards, Away Total Passes, Away Tackles, Away Attacks, Away Dangerous Attacks]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add a prefix to identefy which team the stat belongs to.\n",
    "home_titles = ['Home ' + sub for sub in actual_titltes]\n",
    "away_titles = ['Away ' + sub for sub in actual_titltes]\n",
    "all_titles = home_titles + away_titles\n",
    "\n",
    "\n",
    "info_columns = ['Info','Date','Home','Away','FTHG','FTAG'] \n",
    "all_columns = info_columns + all_titles\n",
    "\n",
    "df = pd.DataFrame(columns=all_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info</th>\n",
       "      <th>Date</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>Home Ball Possession</th>\n",
       "      <th>Home Goal Attempts</th>\n",
       "      <th>Home Shots on Goal</th>\n",
       "      <th>Home Shots off Goal</th>\n",
       "      <th>...</th>\n",
       "      <th>Away Corner Kicks</th>\n",
       "      <th>Away Offsides</th>\n",
       "      <th>Away Goalkeeper Saves</th>\n",
       "      <th>Away Fouls</th>\n",
       "      <th>Away Red Cards</th>\n",
       "      <th>Away Yellow Cards</th>\n",
       "      <th>Away Total Passes</th>\n",
       "      <th>Away Tackles</th>\n",
       "      <th>Away Attacks</th>\n",
       "      <th>Away Dangerous Attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Championship - Round 18</td>\n",
       "      <td>12.12.2020 09:00</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Watford</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45%</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>386</td>\n",
       "      <td>15</td>\n",
       "      <td>113</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Championship - Round 18</td>\n",
       "      <td>12.12.2020 09:00</td>\n",
       "      <td>Derby</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62%</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>11</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Championship - Round 18</td>\n",
       "      <td>12.12.2020 09:00</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49%</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>463</td>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Championship - Round 18</td>\n",
       "      <td>12.12.2020 09:00</td>\n",
       "      <td>Derby</td>\n",
       "      <td>Stoke</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62%</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>11</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Championship - Round 18</td>\n",
       "      <td>12.12.2020 09:00</td>\n",
       "      <td>Luton</td>\n",
       "      <td>Preston</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>46%</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357</td>\n",
       "      <td>21</td>\n",
       "      <td>90</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Info              Date         Home          Away FTHG  \\\n",
       "0  Championship - Round 18  12.12.2020 09:00   Birmingham       Watford    0   \n",
       "1  Championship - Round 18  12.12.2020 09:00        Derby         Stoke    0   \n",
       "2  Championship - Round 18  12.12.2020 09:00  Bournemouth  Huddersfield    5   \n",
       "3  Championship - Round 18  12.12.2020 09:00        Derby         Stoke    0   \n",
       "4  Championship - Round 18  12.12.2020 09:00        Luton       Preston    3   \n",
       "\n",
       "  FTAG Home Ball Possession Home Goal Attempts Home Shots on Goal  \\\n",
       "0    1                  45%                  9                  2   \n",
       "1    0                  62%                 11                  5   \n",
       "2    0                  49%                 13                  8   \n",
       "3    0                  62%                 11                  5   \n",
       "4    0                  46%                 19                  5   \n",
       "\n",
       "  Home Shots off Goal  ... Away Corner Kicks Away Offsides  \\\n",
       "0                   5  ...                 6             2   \n",
       "1                   3  ...                 3             1   \n",
       "2                   3  ...                 2             2   \n",
       "3                   3  ...                 3             1   \n",
       "4                  10  ...                 4             2   \n",
       "\n",
       "  Away Goalkeeper Saves Away Fouls Away Red Cards Away Yellow Cards  \\\n",
       "0                     2         10              0                 1   \n",
       "1                     5         14            NaN                 1   \n",
       "2                     3          8            NaN                 1   \n",
       "3                     5         14            NaN                 1   \n",
       "4                     2          7            NaN               NaN   \n",
       "\n",
       "  Away Total Passes Away Tackles Away Attacks Away Dangerous Attacks  \n",
       "0               386           15          113                     43  \n",
       "1               310           11           95                     34  \n",
       "2               463           16          114                     48  \n",
       "3               310           11           95                     34  \n",
       "4               357           21           90                     36  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "#Rememeber you can get statistics from half, Second and complete macth by changing statistics_time \n",
    "complete = 'tab-statistics-0-statistic'\n",
    "first_half = 'tab-statistics-1-statistic'\n",
    "second_half ='tab-statistics-2-statistic'\n",
    "statistics_time = complete\n",
    "\n",
    "\n",
    "for soup in list_soups:\n",
    "    try:\n",
    "        info = soup.findAll('span',{'class':'description__country'})[0].a.text\n",
    "    except:\n",
    "        info = np.nan\n",
    "    \n",
    "    try:\n",
    "        date = soup.findAll('div',{'id':'utime'})[0].text\n",
    "    except:\n",
    "        date = np.nan\n",
    "    \n",
    "    try:\n",
    "        home = soup.findAll('div',{'class':'team-text tname-home'})[0].a.text\n",
    "    except:\n",
    "        home = np.nan\n",
    "    \n",
    "    try:\n",
    "        away = soup.findAll('div',{'class':'team-text tname-away'})[0].a.text\n",
    "    except:\n",
    "        away = np.nan\n",
    "\n",
    "    try:  \n",
    "        match_result = soup.find_all(\"div\", {\"id\":\"event_detail_current_result\"})[0]\n",
    "        scores = match_result.findAll('span',{'class':'scoreboard'})\n",
    "        score = [score.text for score in scores]\n",
    "        home_score = score[0]\n",
    "        away_score = score[1]\n",
    "    except:\n",
    "        home_score = np.nan\n",
    "        away_score = np.nan\n",
    "        \n",
    "    #try:\n",
    "    match = soup.findAll('div', {'id':statistics_time})[0]\n",
    "\n",
    "    home_values = match.findAll('div', {'class':'statText statText--homeValue'})\n",
    "    home_value = [home.text for home in home_values]\n",
    "\n",
    "    away_values = match.findAll('div', {'class':'statText statText--awayValue'})\n",
    "    away_value = [away.text for away in away_values]\n",
    "\n",
    "    #---------------\n",
    "    titles = match.findAll('div',{'class':'statText statText--titleValue'})\n",
    "    #List with all the titles\n",
    "    actual_titltes = [title.text for title in titles]\n",
    "    \n",
    "    #except:\n",
    "    #   home_value = []\n",
    "    #   away_value = []\n",
    "    #   actual_titltes = []\n",
    "        \n",
    "\n",
    "    #add a prefix to identefy which team the stat belongs to.\n",
    "    home_titles = ['Home ' + sub for sub in actual_titltes]\n",
    "    away_titles = ['Away ' + sub for sub in actual_titltes]\n",
    "    all_titles = home_titles + away_titles\n",
    "\n",
    "    all_columns = info_columns + all_titles\n",
    "        #----------------------------------------------------------\n",
    "\n",
    "    #dataframe values\n",
    "    match_data = [info, date, home, away, home_score, away_score]\n",
    "    all_values = match_data + home_value + away_value\n",
    "\n",
    "    #create a dictionary\n",
    "    keys_list = all_columns \n",
    "    values_list = all_values\n",
    "    zip_iterator = zip(keys_list, values_list)\n",
    "    match_dictionary = dict(zip_iterator)\n",
    "\n",
    "    #append values in the dataframe\n",
    "    df = df.append( match_dictionary,  ignore_index = True)\n",
    "    #print ( 'NOT found list_soups[{}]'.format(count) )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the data is right, it is time to save the file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Championship_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Read it in case of error:</b> \n",
    "1. rename the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the code again (#scraping code) using the error list.\n",
    "3. Create a new empy dataframe with the column names\n",
    "4. Fill the dataframe\n",
    "5. Combine the new dataframe with the previous one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2 = pd.concat([df_all, df], ignore_index=True) \n",
    "df_all2\n",
    "#df_all2.to_csv('Championship_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Repeat this error proces as necesary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
